\documentclass{article}
\bibliographystyle{alpha}
\usepackage{url}
\newcommand{\lp}{$\lambda$Prolog}

\title{{\Huge A User Guide Bedwyr}
%   \thanks{This document still needs a lot of improvements.}
}
\author{David Baelde, Andrew Gacek, Dale Miller, \\
        Gopalan Nadathur, Alwen Tiu}

\begin{document}
\maketitle

\tableofcontents

\vfill

\paragraph{Why this name?}
In the legend of King Arthur and the round table, several knights
shared in the search for the holy grail.  The name of one of them,
Parsifal, is used for an INRIA team associated with the ``Slimmer''
effort.  Bedwyr was another one of those knights.  Wikipedia (using
the spelling ``Bedivere'') mentions that Bedwyr appears in {\em Monty
Python and the Holy Grail} where he is ``portrayed as a master of the
extremely odd logic in the ancient times, whom occasionally blunders."
Bedwyr is a re-implementation and rethinking of an earlier system
called Level 0/1 written by Alwen Tiu and described in
\cite{tiu05eshol}.  For more information, see
\url{http://www.lix.polytechnique.fr/parsifal/} and
\url{http://slimmer.gforge.inria.fr/}.


% ============================================================================
\newpage
\section{Get Bedwyr}
\label{sec:install}

You can get Bedwyr from Slimmer's INRIA Gforge project page:
\url{http://gforge.inria.fr/projects/slimmer}.
There you can download tarballs or get the development version using SVN
| instructions are provided on the project page.  The development of
Bedwyr is meant to be an open source project.  If you are keen
to work on the source code and/or examples, please contact
one of the ``Project Admins'' of the project (as listed at the above url).

\subsection{Distribution layout}

The Bedwyr distribution is organized as follows:

\begin{tabular}{r@{\quad}l}
  \texttt{/src}      & Source code \\
  \texttt{/doc}      &  Documentation | you're reading it \\
  \texttt{/examples} &  Examples | reading them helps
\end{tabular}

\subsection{Build}

Bedwyr's only dependency is the OCaml compiler suite.
Then, the procedure is quite simple.

\begin{verbatim}
# ./configure
# make
\end{verbatim}

You'll get the bedwyr executable in \texttt{src/bedwyr}.

\subsection{Test}

\begin{verbatim}
Testing the core library:
# make -C src test
More tests, including examples in Bedwyr:
# make test
\end{verbatim}

\subsection{Line editing}

By default, Bedwyr is built using the native-code compiler \texttt{ocamlopt},
since it is much faster. If you don't have it or don't want it (e.g.
for easier debugging) use \texttt{./configure --disable-native-code}.

Bedwyr has no line editing facilities at all. We recommend using \texttt{ledit}
for a nicer experience. Get it (from your usual package manager of at
(\url{ftp://ftp.inria.fr/INRIA/cristal/Daniel.de_Rauglaudre/Tools})
and simply run \texttt{ledit src/bedwyr}.

\subsection{Emacs mode}

Assuming Bedwyr sits in your \verb.~/bedwyr. directory,
you can use the Emacs mode for Bedwyr by adding these two lines to your
\verb,~/.emacs, file:
\begin{verbatim}
(load "~/bedwyr/contrib/bedwyr.el")
(setq bedwyr-program "~/bedwyr/src/bedwyr")
;; Of course you can change both locations to wherever you want.
\end{verbatim}

Then you should be able to load any \verb:.def: file
and have syntax highlighting and some rough auto-indenting.
Also if you do \verb.C-c C-c. it will start Bedwyr
and load the current file you are working on.

% ============================================================================
%\newpage
\section{User interface}
\label{sec:interface}

The concrete syntax of formulas in Bedwyr resemble that used by
$\lambda$Prolog in, say, the Teyjus implementation
\cite{nadathur99cade}.  While both systems implement aspects of
higher-order logic programming, they are rather different systems.
The most striking difference between these systems is that
$\lambda$Prolog accepts the ``open-world assumption'': thus, any
conclusions drawn in (the logic of) $\lambda$Prolog will hold in any
extension of the underlying logic programming language.  Bedwyr on the
contrary accepts the ``closed-world assumption'': the notion of
programs are replaced by {\em definitions} that capture the
``if-and-only-if'' closure of logic programs.  This change allows
Bedwyr to give a computational interpretation to finite failure and to
allow it do deduction that encodes model checking.

\subsection{Syntax}

Bedwyr uses HOAS (Higher-Order Abstract Syntax), which means that
formulas of the Linc logic and of the object logics are represented
using $\lambda$-terms. Term normalization ($\beta$-reduction) is
implicit and the equality of terms is given by
$\alpha\beta\eta$-conversion.

The grammar for formulas and terms is given in Figure~\ref{concrete}.
The abstraction over variable \verb.x. in \verb.term. is denoted by
\verb.x\term. | which is read as $\lambda x. term$. On top of that we
build formulas: e.g. we write \verb.pi x\ x=x.  (that is
$pi\;(\lambda{}x.(=\;x\;x))$) to represent $\forall x. x=x$.  The
scope of the infix $\lambda$-abstraction extends to the right as far
as possible: the term \verb.(x\ y\ f y x)). is parenthesized as 
\verb.(x\ (y\ ((f y) x))).

\begin{figure}
\[\begin{array}{rclp{5cm}}
form &::=& form \texttt{,}  form & conjunction \\
     & | & form \texttt{;}  form & disjunction \\
     & | & form \texttt{=>} form & implication \\
     & | & \verb.pi x\.    form  & universal quantification over $x$ \\
     & | & \verb.sigma x\. form  & existential quantification over $x$ \\
     & | & \verb.nabla x\. form  & generic quantification over $x$ \\
     & | & atomic & definition \\
     & | & term \verb.=. term & equality \\
term &::=& id & identifiers are non-empty sequences of \verb.[A-Za-z0-9/_']. \\
     & | & term \; term+ & application \\
     & | & id \verb.\. term & abstraction \\
     & | & term \; infix \; term & infix operators are
             \verb.+., \verb.-., \verb.*., \verb.->. and \verb.<-.. \\
     & | & \verb.(. term \verb.). & \\
atomic &::=& id \; term* & a possibly empty application with a constant head \\
\end{array}\]
\caption{Grammar for formulas and terms..}
\label{concrete}
\end{figure}

\subsection{Running Bedwyr}

When you run Bedwyr, it will load a collection of definitions,
against which you'll then be able to ask queries.
In queries, variables starting with an uppercase character (\verb.A-Z_.)
are implicitly quantified existentially, and their instantiations in solutions
are displayed.

In the following example we load a set of 
definitions and check a theorem about it: $\lambda x.x\;x$ has no simple type.

\begin{verbatim}
dbaelde@poum bedwyr % src/bedwyr examples/lambda.def
[...welcome message...]
?= (sigma T\ wt nil (abs x\ app x x) T) => false.
Yes.
More [y] ? y
No more solutions.
?= pi x\ X x = x x.
Solution found:
 X = (x1\x1 x1)
More [y] ? y
No more solutions.
\end{verbatim}

\subsubsection{Definition files}

Definition files are usually named with a \verb|.def| extension.
You can find several of them in the \verb.examples. directory
of the Bedwyr distribution.
Definitions are to be defined as a set of clauses, in which uppercase
variables are implicitly universally quantified:
\[ clause ::= atomic \;\verb.:=.\; term \verb|.| \]

Definition files may also contain include commands:
\begin{verbatim}#include "another/file.def".\end{verbatim}

Finally, if the head of the clause is missing, the body will be processed as a 
query.

\subsubsection{Session management commands}

Several commands alter the internal set of definitions of Bedwyr:
\verb.#include., \verb.#session., \verb.#reload. and \verb.#reset..
\begin{itemize}
  \item
    \verb.#include. is meant to be used in \verb;.def; files.
  \item
    \verb.#session. is a better \verb.#include. meant for query mode.
    It accepts any number of filenames as parameters, and this set of files
    will be remembered as the current \emph{session}.
    When you pass filenames on Bedwyr's command line,
    it is equivalent to call \verb.#session. with these definition files.
  \item
    \verb.#reload. clears all the definitions,
    and then reloads all the session's files. It is useful if they have 
    been changed.
  \item
    \verb.#reset. clears all the definitions and empties the session.
\end{itemize}

% ============================================================================
%\newpage
\section{How to use Bedwyr}
\label{sec:howto}

A better understanding of the tool is probably needed to get your work
done. 

\subsection{Proof-search within LINC}
\label{psearch}

LINC is a logic developed over the past few years.  The acronym, which
stands for ``lambda, induction, nabla, and co-induction'', lists the
main novel components of the logic.  In particular, $\lambda$-terms
are supported directly (and, hence, the $\lambda$-tree syntax approach
to higher-order abstract syntax is supported \cite{miller00cl}).
Induction and co-induction are also available.  The nabla $\nabla$
quantifier has be added to this logic in order to increase the
expressiveness of programs using hoas in negated situations.  The
proof theory of LINC is given in \cite{miller05tocl,tiu04phd}.

Bedwyr is a proof search engine for a small fragment of the LINC
logic.  In principle, Bedwyr uses two provers.  Prover 1 is similar to
a depth-first interpreter used in in $\lambda$Prolog.  The main
difference is in the proof of an implication.  
To prove an implication $A\Rightarrow B$, prover 1  calls prover 0
to enumerates all possible solutions
$\{\theta_i\;|\;i=1,\ldots,n\}$ for $A$, 
and then prover 1 tries to prove $B\theta_1\wedge\dots\wedge B\theta_N$.
If $A$ has no solution (that is, if $n=0$), the implication is true.
The substitutions generated by prover 1 are for ``logic variables'' in
the sense that is usual for logic programming implementations.  On the
other hand, the substitutions generated by prover 0 are for
eigenvariables. 

Two run-time errors can occur during proof search in Bedwyr.  The first
is when either prover encounters a unification problem that is not a 
higher-order pattern unification: full higher-order unification is not
implemented (as is done in $\lambda$Prolog).  The second error can
occur when a logic variable from prover 1 appears on the left of an
implication: prover 0 does not know what to do with such variables.

Examples will help to understand the second one:
\begin{verbatim}
?= X = 1 => X = 1.
Error: logic variable on the left
?= X=1, pi x\ x = X => x = X.
Solution found:
 X = 1
More [y] ? y
No more solutions.
?= 
\end{verbatim}
The first query requires radically different tools than those we use |
namely, disunification. (The cryptic message about ``on the left''
refers to the left of the sequent arrow in the proof theory of LINC.)
The query actually has infinitely many solutions: any term other than
$1$ can be used to instantiate $X$.  In the second query works since
\verb.X. is instantiated at the time the implication is processed.

\subsection{Tabling}

Until now, all definitions (inductive, co-inductive or non-recursive)
are treated the same way, loops can occur in the proof-search, and Bedwyr
won't avoid them. Also, Bedwyr can do the same search several times without
noticing. To solve that, we use tabling.

Although quite weak, tabling in Bedwyr is already a great improvement.
It is still under work.

For tabled definitions, being inductive of co-inductive matters, and this 
matters only for tabled definitions.
Tabling is thus enabled by prepending the \texttt{inductive} or
\texttt{coinductive} keyword to \emph{every} clause of the definition |
even if the definition is non-recursive.

For now, tabling only applies to goals which do not contain logic variables.
Then, loops are successes for coinductive definitions,
and failures for inductive ones.


\section{The logic behind Bedwyr}
\label{logic}

The logic behind Bedwyr is an extension to a higher-order version of
intuitionistic logic.  Below we provide a high-level overview of the
logical aspects of Bedwyr that differentiate it from (the logics
underlying) \lp\ and Prolog.  More explicit information on this system
can be found in \cite{tiu05eshol}: n.b., the name ``Level 0/1'' in
that paper has now been replaced by Bedwyr.


\paragraph{Built-in treatment of bindings}
Bedwyr treats $\lambda$-abstractions within terms as primitive as well
as allowing for variables of function type and quantifiers within
formulas ($\forall$, $\exists$, $\nabla$).  The system's two provers
both implement ``higher-order pattern unification'' (also called
$L_\lambda$-unification) \cite{miller91jlc}.   This kind of unification
appears to be the weakest extension to first-order unification that
treats bindings as a primitive.  A number of ``proof search'' systems
implement this kind of unification (eg, Twelf, Teyjus, Coq, and
Minlog).  Full $\beta$-conversion is implemented by Bedwyr as well.
As a result, {\em higher-order abstract syntax} is fully supported.
\lp\ similarly implements all these features, although \lp\ implements
full higher-order unification (that is, it is not restricted to the
$L_\lambda$ subset).  Another different with \lp\ is that Bedwyr does
not have a built-in notion of types, while \lp\ is simply typed.

\begin{figure}
\begin{verbatim}
% The predicate a holds for 3, 5, and 2.
a (s (s (s z))).
a (s (s (s (s (s z))))).
a (s (s z)).

% The less-than-or-equal relation
leq z N.
leq (s N) (s M) := leq N M.

% Compute the maximum of a
maxa N := a N, pi x\ a x => leq x N.
\end{verbatim}
\caption{Computing the maximum of a defined predicate.}
\label{maxa}
\end{figure}

\paragraph{Syntax and semantics of clauses}
Clauses in Bedwyr resemble those in \lp, but the underlying proof
search semantics of those clauses can differ significantly.  For example,
consider the Bedwyr program in Figure~\ref{maxa}.  These clauses are
identical to those in \lp\ except for the use of \verb+:=+ instead of
\verb+:-+.  Actually the ``proof search semantics'' for all but the
last clause above is the same in Bedwyr and \lp\ (and, in this case,
Prolog too).  The last clause, however, has an implication \verb+=>+
in the goal, something also allowed in \lp.  During proof search,
however, this occurrence of the implication in \lp\ causes the current
program to be extended with an atomic fact of the form \verb+(a c)+,
where {\tt c} is a new eigenvariable of the proof search.  In reality,
\lp\ uses the ``open-world assumption'': it adds a new item {\tt c}
and a new fact about it {\tt (a c)}.  In such a new world, however, the 
{\tt leq} relation to does not have any information about this
``non-standard'' number {\tt c}.  In contrast to this, Bedwyr will
take the assumption  {\tt (a c)} and ask ``Given the assumption that 
{\tt (a c)} is true, how could it have been proved?''  The natural
answer to this is that that assumption could have been proved if {\tt
c} was either 3 or 5 or 2.  Thus, this analysis will cause a case
analysis: in particular, the query {\tt (maxa N)} will cause the
following goals to be considered:
\begin{verbatim}
        (a N)     (leq 3 N)    (leq 5 N)    (leq 2 N)
\end{verbatim}
The usual approach to unification and depth-first proof search will
now produce the proper maximum value.

\bigskip
There are two orthogonal extensions to higher-order intuitionistic
logic that have been incorporated into Bedwyr.   We describe them next.

\paragraph{Symmetry of finite success and finite failure}
The underlying logic of {\em fixed points} (also known as {\em
definitions})
\cite{girard92mail,schroeder-Heister93lics,mcdowell03tcs,momigliano03types}
contains an inference rule that allows for failure in unification
(and, hence, in simple proof search) to be turned into a success.
Thus, simple forms of ``negation-as-failure'' can be naturally
captured in Bedwyr and the underlying logic.  It is also possible to
describe both {\em may} and {\em must} behaviors in process calculi.
For example, not only can one code reachability in process calculus
but bisimulation is also possible.  One way to view this enhancement
to proof search is the following: Let $A$ and $B$ be two atomic
formulas.  Then, finite success is captured by proving the sequent
$\longrightarrow A$, finite failure is captured by proving the sequent
$A\longrightarrow$, and simulation is captured by proving the sequent
$A\longrightarrow B$.

\paragraph{The $\nabla$ quantifier}
In order to treat specifications using higher-order abstract syntax
properly, it appears that a new quantifier, called $\nabla$, is
necessary.  If finite success is all that is needed, the $\nabla$ can
be replaced with the universal quantifier.  When finite failure is
involved, however, the $\nabla$ quantifier plays an independent role.
See \cite{miller05tocl,tiu04phd,tiu05concur} for more on this
quantifier.  It is worth pointing out that we know of no examples
involving $\nabla$ that do not also involve hoas.

\section{Examples of Bedwyr code}

\begin{flushright}
Few things are harder to put up with than\\
the annoyance of a good example.\\
    -- Mark Twain
\end{flushright}

The distribution of Bedwyr comes with several examples of its use.
These examples can be divided classified roughly as follows.

\begin{description}
\item[Basic examples] These examples are small and illustrate some
  simple aspects of the system.

\item[Model checking] Some simple model-checking-style examples are
  provided. 

\item[Games] Bedwyr allows for a simple approach to explore for
  winning strategies in some simple games, such as tic-tac-toe.

\item[$\lambda$-calculus] Various relations and properties of the
  $\lambda$-calculus are developed in some definition files.

\item[Simulation and bisimulation] These relationships between
  processes where an important class of examples for which the theory
  behind Bedwyr was targeted.  Examples of checking simulation is done
  for abstract transition systems, value-passing CCS, and the
  $\pi$-calculus.  The $\pi$-calculus examples are of particular note:
  all side-conditions for defining the operational semantics and
  bisimulation are handled directly and declaratively by the logic
  underlying Bedwyr.   Modal logic for the $\pi$-calculus is also
  illustrated by an example definition file.

\end{description}

\subsection{The $\pi$-calculus example in more detail}

To give on a quick illustration of one of these examples and who they
can be used, consider the implementation of the $\pi$-calculus that is
contained in the example file named \verb+pi.def+.  Of the several
things defined in that file, the operational semantics for the
$\pi$-calculus given as using one-step transitions: for a specific
example, see Figure~\ref{one-step}.  First notice that the syntax of
clauses is almost identical to that used in $\lambda$Prolog.  In
particular, the backslash is used to denote the $\lambda$-binder.  The
main syntactic difference is that the head and body of clauses are
separated from either other using the \verb+:=+ instead of the
\verb+:-+ (reverse turnstile).  The former symbol is used to remind
the Bedwyr user that programs are used to define ``if and only if''
completions of specifications (whereas, in \lp\ the \verb+:-+ is the
more usual ``if'' interpretation).  Unlike \lp, Bedwyr is
untyped so there are no {\tt kind} and {\tt type} declarations and no
static checking of your source code.  

Beyond the syntactic differences, the operational semantics of \lp\
and Bedwyr differ significant.  If a specification is simply a Horn
clause program, the two systems coincide.  In operational
interpretation of an implication differs significantly: in Bedwyr, to
prove $A\supset B$, all possible ways to prove $A$ are explored and
for each answer substitution $\theta$ that is found, the goal
$B\theta$ is attempted (see Section~\ref{psearch}).  Bedwyr also
contains the $\nabla$-quantifier \cite{miller05tocl}. 

\begin{figure}
\begin{verbatim}
onep (in X M)    (dn X) M.
one  (out X Y P) (up X Y) P.
one  (match X X P) A Q := one P A Q.
onep (match X X P) A M := onep P A M.
one  (nu x\P x) A (nu x\Q x) := nabla x\ one  (P x) A (Q x).
onep (nu x\P x) A (y\ nu x\Q x y) := 
                           nabla x\ onep (P x) A (y\ Q x y).
one (par P Q) tau (par R T) :=
  sigma X\ sigma Y\ sigma M\ onep P (dn X) M &
                             one Q (up X Y) T & R = (M Y).
one (par P Q) tau (par R T) :=
  sigma X\ sigma Y\ sigma M\ onep Q (dn X) M &
                             one P (up X Y) R & T = (M Y).
\end{verbatim}
\caption{Some lines in {\tt pi.def} used to define one-step
  transitions.  See the example file for the full definition.}
\label{one-step}

\begin{verbatim}
coinductive bisim P Q :=
   (pi A\ pi P1\ one P A P1 => sigma Q1\ one Q A Q1 &
                                         bisim P1 Q1) &
   (pi X\ pi M\  onep P (dn X) M => sigma N\ onep Q (dn X) N & 
                                     pi w\ bisim (M w) (N w)) &
   (pi X\ pi M\ onep P (up X) M => sigma N\ onep Q (up X) N &
                                     nabla w\ bisim (M w) (N w)) &
   (pi A\ pi Q1\ one Q A Q1 => sigma P1\ one P A P1 & 
                                         bisim Q1 P1) &
   (pi X\ pi N\  onep Q (dn X) N => sigma M\ onep P (dn X) M & 
                                     pi w\ bisim (N w) (M w)) &
   (pi X\ pi N\ onep Q (up X) N => sigma M\ onep P (up X) M &
                                     nabla w\ bisim (N w) (M w)).
\end{verbatim}
\caption{The definition of (open) bisimulation.}
\label{bisim}
\end{figure}

Returning to the example in Figure~\ref{one-step}, notice that two
predicates are defined: {\tt one} and {\tt onep}.  The first one
relates a processes, an action, and a process.  The first relates a 
processes, an abstractions of an action, and an abstraction of a
process.  The {\tt one} predicate is used to capture ``free
transitions'' and the ``$\tau$-transition'' while the second is used
to capture bounded transitions.  See \cite{tiu04fguc,tiu05concur} for
more details on this encoding strategy for the $\pi$-calculus.

Figure~\ref{bisim} provides all that is necessary to specify (open)
bisimulation for (finite) $\pi$-calculus.  The keyword {\tt
coinductive} tells the system that it will be attempting to explore a
greatest fixed point.  The other cases should look natural, at least
once one understand the $\lambda$-tree approach to representing syntax
and the use of the $\nabla$-quantifier.  The main thing to point out
here is that in the specification, no special side conditions need to
be added to the system: all the familiar side conditions from the
usual papers on the $\pi$-calculus are treated by the implementation
of the Bedwyr logic: the user of the system no longer needs to deal
with them explicitly but implicitly and declaratively (via quantifier
scope, $\alpha\beta\eta$-conversion, etc).

It is now possible to test some simple examples in the system.  For
example,
\begin{verbatim}
$ src/bedwyr examples/pi.def
Bedwyr welcomes you....

?= bisim (in a x\ in a y\ z) (in a x\ nu z\ in a y\ z).
Yes.
More [y] ? y
No more solutions.
?= bisim (in a x\ nu y\ match x y\ out c c z) (in a x\ z).
Yes.
More [y] ? y
No more solutions.
?= bisim (nu x\ out a x (in c y\ match x y (out c c z)))
                (nu x\ out a x (in c y\ z)).
No.
?= 
\end{verbatim}
These query prove that 
$a(x).a(y).0$ and $a(x).(\nu z).a(y).z$ are bisimilar, 
that
$a(x).(\nu y).[x=y].c!c.0$ and $a(x).0$ are bisimilar, and that 
$(\nu x).a!x.c(y).[x=y].c!c.0$ and 
$(\nu x).a!x.c(y).0$ are not bisimilar.

% Link's to Dale's bibref file.  After Dale runs the aux2bib (see Makefile),
% then one can use the local userguide.bib file.
\bibliography{../../../../../pap/references/master}

%\bibliography{userguide}

\end{document}
